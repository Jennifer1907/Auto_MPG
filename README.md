# Auto MPG Regression with PyTorch â€” Full MLP Pipeline + Deep Insights

This repository implements a complete regression workflow using **PyTorch**, applied to the classic **Auto MPG** dataset.  
Rather than just providing code, this README explains **why each design choice matters**, including tensor shapes, architecture depth, optimizer logic, and metric computation.

It is written for learners who want to understand PyTorch deeply and build correct, production-grade training loops.

---

# ğŸ§± 1. Project Overview

We build a model to predict **Miles Per Gallon (MPG)** using a fully connected neural network (MLP), achieving **R-square ~ 90%**. 

The dataset includes attributes such as:
- weight  
- displacement  
- horsepower  
- cylinders  
- acceleration  
- model year  

Model architecture:

```
Input â†’ Linear â†’ ReLU â†’ Linear â†’ ReLU â†’ Linear â†’ Output
```

Hidden sizes: 64 â†’ 32  
Output size: 1

---

# âš™ï¸ 2. Run Instructions

Install dependencies:

```bash
pip install torch numpy pandas scikit-learn
```

Run the project:

```bash
python auto_mpg_mlp_regression.py
```

Ensure that the file:

```
Auto_MPG_data.csv
```

is placed in the same directory or adjust the `csv_path`.

---

# ğŸ“ 3. Project Structure

```
auto_mpg_mlp_regression.py
Auto_MPG_data.csv
README.md
```

---

# ğŸ§ª 4. Evaluation Metric â€” RÂ² Score

We compute:

$ R^2 = 1 - \frac{SS_{res}}{SS_{tot}} $

Include:
- $SS_{res} = \sum (y_{true} - y_{pred})^2$ 
- $SS_{tot} = \sum (y_{true} - y_{mean})^2$ 

---


# ğŸ§© 5. Key Theoretical Insights (Q1 â†’ Q6)

This section answers every conceptual question tied to the training pipeline.

---

## âœ… (1) Why do we need:

```python
y_true = y_true.view(-1).float()
y_pred = y_pred.view(-1).float()
```

### âœ” 1. Avoid silent shape broadcasting bugs
`fc3` produces output `(B,1)`, while many parts of the pipeline use `(B,)`.

If shapes mismatch:

```
(B,1) - (B,)  â†’  PyTorch broadcasts to (B,B)
```

This results in:
- wrong SS_res  
- wrong SS_tot  
- wrong RÂ²  
- NO error thrown  

Therefore we flatten tensors to 1D:

```
(B,1) â†’ (B,)
```

### âœ” 2. Ensure floating-point math
If labels are accidentally `LongTensor`, subtraction and division behave incorrectly.  
`.float()` ensures numeric stability.

---

## âœ… (2) Difference between these two MLP definitions:

### Style A â€” two hidden layers

```python
self.fc1 = nn.Linear(input_dim, h1)
self.fc2 = nn.Linear(h1, h2)
self.fc3 = nn.Linear(h2, output_dim)
```

### Style B â€” one hidden layer

```python
self.linear1 = nn.Linear(input_dim, hidden_dim)
self.activation = nn.ReLU()
self.linear2 = nn.Linear(hidden_dim, output_dim)
```

### âœ” Insight:
Naming (`fc1` vs `linear1`) is **irrelevant**.

What matters is:
- Style A defines **two hidden layers**
- Style B defines **one hidden layer**

Two hidden layers allow deeper, more expressive models.

---

## âœ… (3) Why two hidden layers instead of one?

### âœ” 1. Function complexity
Auto MPG relationships are nonlinear:
- weight Ã— horsepower interactions  
- displacement Ã— year effects  
- cylinders Ã— acceleration interactions  

One hidden layer *can* approximate any function but may require hundreds of neurons.  
Two hidden layers approximate complex functions with **fewer parameters** and more stability.

### âœ” 2. Hierarchical feature learning
Layer 1: learns primitive combinations  
Layer 2: learns higher-order combinations  

This mimics deep learning structure.

### âœ” 3. Educational purpose
Assignments often require two layers to illustrate:
- stacking nonlinearities  
- architecture depth  
- training dynamics  

---

## âœ… (4) Why use:

```python
x = x.squeeze(1)
```

### âœ” Reason:
`fc3` outputs `(B,1)` but computation of:

- MSE  
- RÂ²  
- plotting  
- metric logging  
- loss curves  

all expect `(B,)`.

If not squeezed:
```
outputs shape = (B,1)
targets shape = (B,)
```

Then:

```
(B,1) - (B,)  â†’ (B,B) broadcasting
```

This silently corrupts:
- loss  
- gradients  
- RÂ²  

Fix: remove the redundant dimension:

```
(B,1) â†’ (B,)
```

---

## âœ… (5) SGD vs Adam â€” which to choose?

### âœ” Why Adam is better here:
Adam uses *adaptive learning rates* and *momentum*:

### Why Adam is better here:

Adam uses _adaptive learning rates_ and _momentum_:

**Momentum estimate:**
$
m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t
$

**Variance estimate:**
$
v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2
$

**Bias correction:**
$
\hat{m}_t = \frac{m_t}{1 - \beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1 - \beta_2^t}
$

**Update rule:**
$
\theta_t = \theta_{t-1} - \alpha \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
$

### âœ” Intuition:
- If gradient direction is consistent â†’ larger step  
- If gradient varies wildly â†’ smaller step  
- Each parameter gets its own learning rate  
- Faster convergence than SGD  
- Less hyperparameter tuning  

### âœ” Why not SGD?
SGD requires:
- learning rate schedule  
- momentum tweaking  
- more training epochs  

For structured/tabular data like Auto MPG â†’  
ğŸ‘‰ **Adam is superior and more stable.**

---

## âœ… (6) Why append predictions & targets *inside* the training loop?

### âœ” 1. RÂ² requires all predictions across the epoch  
You cannot compute RÂ² per batch.

### âœ” 2. `.detach()` prevents memory leak  
Without it, the entire autograd graph accumulates â†’ GPU OOM.

### âœ” 3. `.cpu()` avoids Python list + CUDA issues  
Python lists store CPU tensors efficiently.

### âœ” 4. DataLoader yields batches  
You **must** collect inside the loop:

Correct:
```python
for X_batch, y_batch in train_loader:
    outputs = model(X_batch)
    all_preds.append(outputs.detach().cpu())
```

Incorrect / impossible:
```python
outputs = model(train_loader)
```

---

# ğŸ§¬ 6. Full Pipeline Summary

1. RNG seed setup  
2. Load CSV  
3. Extract target `y` and features `X`  
4. Train/Val/Test split  
5. Standardize data  
6. Convert to PyTorch tensors  
7. Build `CustomDataset`  
8. Create DataLoaders  
9. Define MLP (2 hidden layers)  
10. Train model using Adam + MSE  
11. Track loss and RÂ² each epoch  
12. Evaluate on validation  
13. Test model on final dataset  

---

# ğŸ 7. Final Thoughts

This repository demonstrates:
- correct PyTorch training loop design  
- how to avoid silent broadcasting bugs  
- how Adam works internally  
- why deep MLPs outperform shallow ones  
- how to handle tensor shapes properly  
- best practices for metric computation  
- safe memory handling with `.detach()`  

By understanding these insights, you will write **far more stable, correct, and scalable PyTorch code** for real-world ML projects.

---

# ğŸ‘¤ Author

This README is designed to be:
- educational  
- technically accurate  
- professional  
- suitable for public GitHub repositories  
