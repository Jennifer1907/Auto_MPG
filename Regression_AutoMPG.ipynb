{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0cf1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "random_state = 59\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85385ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\hangu\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yPPJvcMIxFefGK6V75Mn0cqq7FbpgKEu\n",
      "To: c:\\Users\\hangu\\OneDrive\\Documents\\0. Personal documents\\0.6 ML AI\\2. AIO2025\\2.2 Weekly exercise\\12. Auto_MPG\\data_auto_mpg.csv\n",
      "100%|██████████| 15.4k/15.4k [00:00<00:00, 1.05MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data_auto_mpg.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q gdown\n",
    "\n",
    "import gdown\n",
    "\n",
    "# ID file trên Google Drive\n",
    "file_id = \"1yPPJvcMIxFefGK6V75Mn0cqq7FbpgKEu\"\n",
    "\n",
    "# Tạo URL dạng direct download\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "# Tên file bạn muốn lưu về\n",
    "output = \"data_auto_mpg.csv\"   # đổi tên nếu bạn muốn\n",
    "\n",
    "gdown.download(url, output, quiet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66438b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Japan</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "0    18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1    15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2    18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3    16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4    17.0          8         302.0       140.0  3449.0          10.5   \n",
       "..    ...        ...           ...         ...     ...           ...   \n",
       "387  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "388  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "389  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "390  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "391  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     Model Year  Europe  Japan  USA  \n",
       "0            70       0      0    1  \n",
       "1            70       0      0    1  \n",
       "2            70       0      0    1  \n",
       "3            70       0      0    1  \n",
       "4            70       0      0    1  \n",
       "..          ...     ...    ...  ...  \n",
       "387          82       0      0    1  \n",
       "388          82       1      0    0  \n",
       "389          82       0      0    1  \n",
       "390          82       0      0    1  \n",
       "391          82       0      0    1  \n",
       "\n",
       "[392 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv(output)\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab162c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(\"MPG\", axis=1).values\n",
    "y = dataset[\"MPG\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5cea37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "test_size = 0.125\n",
    "is_shuffle = True\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=val_size, random_state=random_state, shuffle=is_shuffle)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train, test_size=test_size, random_state=random_state, shuffle=is_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831ae179",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = StandardScaler()\n",
    "X_train_scaled = normalizer.fit_transform(X_train)\n",
    "X_val_scaled = normalizer.transform(X_val)\n",
    "X_test_scaled = normalizer.transform(X_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb31ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "        self.n_samples = X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd823197",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataset = CustomDataset(X_train_scaled, y_train)\n",
    "val_dataset   = CustomDataset(X_val_scaled,   y_val)\n",
    "test_dataset  = CustomDataset(X_test_scaled,  y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebdfcf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed6f548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        if isinstance(hidden_dim, int):\n",
    "            h1 = h2 = hidden_dim\n",
    "        else:\n",
    "            h1, h2 = hidden_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = x.squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "575b35a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=9, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_scaled.shape[1]\n",
    "model = MLP(input_dim=input_dim, hidden_dim=64, output_dim=1).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2053c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(y_true, y_pred):\n",
    "    y_true = y_true.view(-1).float()\n",
    "    y_pred = y_pred.view(-1).float()\n",
    "\n",
    "    ss_res = torch.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = torch.sum((y_true - torch.mean(y_true)) ** 2)\n",
    "    if ss_tot == 0:\n",
    "        return 0.0\n",
    "    return (1 - ss_res / ss_tot).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19b63ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e58417b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100] Train Loss: 610.7095, Train R2: -9.3316 | Val Loss: 616.7402, Val R2: -9.0984\n",
      "Epoch [1/100] Train Loss: 594.9578, Train R2: -9.0581 | Val Loss: 598.2004, Val R2: -8.7985\n",
      "Epoch [2/100] Train Loss: 575.6774, Train R2: -8.6870 | Val Loss: 570.8436, Val R2: -8.3569\n",
      "Epoch [3/100] Train Loss: 544.0577, Train R2: -8.1528 | Val Loss: 531.0790, Val R2: -7.7162\n",
      "Epoch [4/100] Train Loss: 495.5658, Train R2: -7.3856 | Val Loss: 476.5319, Val R2: -6.8368\n",
      "Epoch [5/100] Train Loss: 436.7393, Train R2: -6.3608 | Val Loss: 406.5802, Val R2: -5.7066\n",
      "Epoch [6/100] Train Loss: 361.0905, Train R2: -5.1152 | Val Loss: 322.2185, Val R2: -4.3377\n",
      "Epoch [7/100] Train Loss: 270.5188, Train R2: -3.6587 | Val Loss: 232.4997, Val R2: -2.8700\n",
      "Epoch [8/100] Train Loss: 188.9214, Train R2: -2.1915 | Val Loss: 150.4982, Val R2: -1.5122\n",
      "Epoch [9/100] Train Loss: 119.2448, Train R2: -0.9912 | Val Loss: 89.4822, Val R2: -0.4800\n",
      "Epoch [10/100] Train Loss: 68.5533, Train R2: -0.1729 | Val Loss: 57.4763, Val R2: 0.0870\n",
      "Epoch [11/100] Train Loss: 48.6325, Train R2: 0.1737 | Val Loss: 44.1045, Val R2: 0.3336\n",
      "Epoch [12/100] Train Loss: 40.3077, Train R2: 0.3025 | Val Loss: 34.9157, Val R2: 0.4856\n",
      "Epoch [13/100] Train Loss: 34.1456, Train R2: 0.4251 | Val Loss: 27.4925, Val R2: 0.5948\n",
      "Epoch [14/100] Train Loss: 28.2189, Train R2: 0.5227 | Val Loss: 21.8385, Val R2: 0.6733\n",
      "Epoch [15/100] Train Loss: 23.5405, Train R2: 0.5998 | Val Loss: 18.3088, Val R2: 0.7228\n",
      "Epoch [16/100] Train Loss: 21.4864, Train R2: 0.6496 | Val Loss: 15.8220, Val R2: 0.7581\n",
      "Epoch [17/100] Train Loss: 18.8793, Train R2: 0.6822 | Val Loss: 14.0364, Val R2: 0.7833\n",
      "Epoch [18/100] Train Loss: 17.0176, Train R2: 0.7103 | Val Loss: 12.6359, Val R2: 0.8019\n",
      "Epoch [19/100] Train Loss: 16.4726, Train R2: 0.7302 | Val Loss: 11.8172, Val R2: 0.8128\n",
      "Epoch [20/100] Train Loss: 14.7165, Train R2: 0.7467 | Val Loss: 11.0701, Val R2: 0.8227\n",
      "Epoch [21/100] Train Loss: 13.7596, Train R2: 0.7597 | Val Loss: 10.3816, Val R2: 0.8319\n",
      "Epoch [22/100] Train Loss: 14.1410, Train R2: 0.7709 | Val Loss: 9.8910, Val R2: 0.8384\n",
      "Epoch [23/100] Train Loss: 13.3963, Train R2: 0.7797 | Val Loss: 9.5520, Val R2: 0.8430\n",
      "Epoch [24/100] Train Loss: 12.4052, Train R2: 0.7882 | Val Loss: 9.2390, Val R2: 0.8468\n",
      "Epoch [25/100] Train Loss: 11.9698, Train R2: 0.7967 | Val Loss: 8.8703, Val R2: 0.8512\n",
      "Epoch [26/100] Train Loss: 11.9568, Train R2: 0.8021 | Val Loss: 8.5712, Val R2: 0.8551\n",
      "Epoch [27/100] Train Loss: 11.6249, Train R2: 0.8083 | Val Loss: 8.3379, Val R2: 0.8584\n",
      "Epoch [28/100] Train Loss: 11.1173, Train R2: 0.8117 | Val Loss: 8.1354, Val R2: 0.8620\n",
      "Epoch [29/100] Train Loss: 10.5280, Train R2: 0.8179 | Val Loss: 7.9375, Val R2: 0.8645\n",
      "Epoch [30/100] Train Loss: 10.3662, Train R2: 0.8224 | Val Loss: 7.6714, Val R2: 0.8680\n",
      "Epoch [31/100] Train Loss: 10.0891, Train R2: 0.8262 | Val Loss: 7.4256, Val R2: 0.8712\n",
      "Epoch [32/100] Train Loss: 10.1079, Train R2: 0.8290 | Val Loss: 7.2225, Val R2: 0.8740\n",
      "Epoch [33/100] Train Loss: 9.8500, Train R2: 0.8325 | Val Loss: 7.0477, Val R2: 0.8767\n",
      "Epoch [34/100] Train Loss: 9.6611, Train R2: 0.8358 | Val Loss: 6.8849, Val R2: 0.8791\n",
      "Epoch [35/100] Train Loss: 9.9496, Train R2: 0.8373 | Val Loss: 6.7480, Val R2: 0.8813\n",
      "Epoch [36/100] Train Loss: 9.7056, Train R2: 0.8403 | Val Loss: 6.6485, Val R2: 0.8825\n",
      "Epoch [37/100] Train Loss: 9.1547, Train R2: 0.8430 | Val Loss: 6.5910, Val R2: 0.8832\n",
      "Epoch [38/100] Train Loss: 9.2756, Train R2: 0.8449 | Val Loss: 6.4748, Val R2: 0.8851\n",
      "Epoch [39/100] Train Loss: 9.1202, Train R2: 0.8457 | Val Loss: 6.4899, Val R2: 0.8844\n",
      "Epoch [40/100] Train Loss: 9.7143, Train R2: 0.8477 | Val Loss: 6.2985, Val R2: 0.8877\n",
      "Epoch [41/100] Train Loss: 8.6816, Train R2: 0.8508 | Val Loss: 6.2176, Val R2: 0.8887\n",
      "Epoch [42/100] Train Loss: 8.6223, Train R2: 0.8521 | Val Loss: 6.1706, Val R2: 0.8894\n",
      "Epoch [43/100] Train Loss: 8.7589, Train R2: 0.8542 | Val Loss: 6.0890, Val R2: 0.8909\n",
      "Epoch [44/100] Train Loss: 8.3884, Train R2: 0.8541 | Val Loss: 6.1031, Val R2: 0.8910\n",
      "Epoch [45/100] Train Loss: 8.6391, Train R2: 0.8562 | Val Loss: 5.9818, Val R2: 0.8925\n",
      "Epoch [46/100] Train Loss: 8.8308, Train R2: 0.8580 | Val Loss: 5.9886, Val R2: 0.8922\n",
      "Epoch [47/100] Train Loss: 8.3602, Train R2: 0.8589 | Val Loss: 5.9162, Val R2: 0.8934\n",
      "Epoch [48/100] Train Loss: 8.4373, Train R2: 0.8604 | Val Loss: 5.8547, Val R2: 0.8945\n",
      "Epoch [49/100] Train Loss: 8.2643, Train R2: 0.8614 | Val Loss: 5.8496, Val R2: 0.8944\n",
      "Epoch [50/100] Train Loss: 8.0875, Train R2: 0.8625 | Val Loss: 5.8103, Val R2: 0.8950\n",
      "Epoch [51/100] Train Loss: 8.0656, Train R2: 0.8635 | Val Loss: 5.7635, Val R2: 0.8958\n",
      "Epoch [52/100] Train Loss: 8.0228, Train R2: 0.8642 | Val Loss: 5.7114, Val R2: 0.8964\n",
      "Epoch [53/100] Train Loss: 7.8688, Train R2: 0.8652 | Val Loss: 5.6488, Val R2: 0.8975\n",
      "Epoch [54/100] Train Loss: 7.6338, Train R2: 0.8661 | Val Loss: 5.6149, Val R2: 0.8982\n",
      "Epoch [55/100] Train Loss: 8.2424, Train R2: 0.8673 | Val Loss: 5.5804, Val R2: 0.8987\n",
      "Epoch [56/100] Train Loss: 8.0491, Train R2: 0.8674 | Val Loss: 5.6219, Val R2: 0.8980\n",
      "Epoch [57/100] Train Loss: 7.4712, Train R2: 0.8689 | Val Loss: 5.6637, Val R2: 0.8974\n",
      "Epoch [58/100] Train Loss: 7.6165, Train R2: 0.8693 | Val Loss: 5.6606, Val R2: 0.8974\n",
      "Epoch [59/100] Train Loss: 7.6046, Train R2: 0.8694 | Val Loss: 5.5894, Val R2: 0.8987\n",
      "Epoch [60/100] Train Loss: 7.5349, Train R2: 0.8705 | Val Loss: 5.5212, Val R2: 0.8995\n",
      "Epoch [61/100] Train Loss: 7.4423, Train R2: 0.8711 | Val Loss: 5.4975, Val R2: 0.9000\n",
      "Epoch [62/100] Train Loss: 7.4876, Train R2: 0.8720 | Val Loss: 5.4613, Val R2: 0.9007\n",
      "Epoch [63/100] Train Loss: 7.2880, Train R2: 0.8724 | Val Loss: 5.4040, Val R2: 0.9016\n",
      "Epoch [64/100] Train Loss: 7.8990, Train R2: 0.8729 | Val Loss: 5.4415, Val R2: 0.9010\n",
      "Epoch [65/100] Train Loss: 7.2903, Train R2: 0.8738 | Val Loss: 5.4455, Val R2: 0.9009\n",
      "Epoch [66/100] Train Loss: 7.3187, Train R2: 0.8736 | Val Loss: 5.4438, Val R2: 0.9009\n",
      "Epoch [67/100] Train Loss: 7.1886, Train R2: 0.8748 | Val Loss: 5.4328, Val R2: 0.9012\n",
      "Epoch [68/100] Train Loss: 7.8020, Train R2: 0.8752 | Val Loss: 5.4390, Val R2: 0.9012\n",
      "Epoch [69/100] Train Loss: 7.5057, Train R2: 0.8757 | Val Loss: 5.3933, Val R2: 0.9018\n",
      "Epoch [70/100] Train Loss: 7.3136, Train R2: 0.8757 | Val Loss: 5.3535, Val R2: 0.9024\n",
      "Epoch [71/100] Train Loss: 7.2994, Train R2: 0.8768 | Val Loss: 5.3432, Val R2: 0.9026\n",
      "Epoch [72/100] Train Loss: 7.1918, Train R2: 0.8772 | Val Loss: 5.3802, Val R2: 0.9021\n",
      "Epoch [73/100] Train Loss: 7.2020, Train R2: 0.8776 | Val Loss: 5.3928, Val R2: 0.9020\n",
      "Epoch [74/100] Train Loss: 7.2432, Train R2: 0.8781 | Val Loss: 5.3230, Val R2: 0.9031\n",
      "Epoch [75/100] Train Loss: 7.3416, Train R2: 0.8783 | Val Loss: 5.3613, Val R2: 0.9024\n",
      "Epoch [76/100] Train Loss: 7.1245, Train R2: 0.8790 | Val Loss: 5.3289, Val R2: 0.9030\n",
      "Epoch [77/100] Train Loss: 7.0821, Train R2: 0.8794 | Val Loss: 5.3318, Val R2: 0.9031\n",
      "Epoch [78/100] Train Loss: 7.1549, Train R2: 0.8791 | Val Loss: 5.2905, Val R2: 0.9037\n",
      "Epoch [79/100] Train Loss: 7.0831, Train R2: 0.8795 | Val Loss: 5.2860, Val R2: 0.9038\n",
      "Epoch [80/100] Train Loss: 6.9266, Train R2: 0.8803 | Val Loss: 5.3114, Val R2: 0.9034\n",
      "Epoch [81/100] Train Loss: 7.1866, Train R2: 0.8808 | Val Loss: 5.2832, Val R2: 0.9039\n",
      "Epoch [82/100] Train Loss: 7.0047, Train R2: 0.8813 | Val Loss: 5.2680, Val R2: 0.9042\n",
      "Epoch [83/100] Train Loss: 6.9847, Train R2: 0.8812 | Val Loss: 5.2830, Val R2: 0.9041\n",
      "Epoch [84/100] Train Loss: 6.9587, Train R2: 0.8807 | Val Loss: 5.2746, Val R2: 0.9042\n",
      "Epoch [85/100] Train Loss: 6.9570, Train R2: 0.8815 | Val Loss: 5.2519, Val R2: 0.9046\n",
      "Epoch [86/100] Train Loss: 7.1949, Train R2: 0.8817 | Val Loss: 5.3014, Val R2: 0.9039\n",
      "Epoch [87/100] Train Loss: 6.9098, Train R2: 0.8830 | Val Loss: 5.2392, Val R2: 0.9048\n",
      "Epoch [88/100] Train Loss: 6.8588, Train R2: 0.8825 | Val Loss: 5.2677, Val R2: 0.9043\n",
      "Epoch [89/100] Train Loss: 6.9550, Train R2: 0.8835 | Val Loss: 5.2249, Val R2: 0.9052\n",
      "Epoch [90/100] Train Loss: 6.9505, Train R2: 0.8836 | Val Loss: 5.2198, Val R2: 0.9053\n",
      "Epoch [91/100] Train Loss: 6.7477, Train R2: 0.8836 | Val Loss: 5.1440, Val R2: 0.9064\n",
      "Epoch [92/100] Train Loss: 6.7931, Train R2: 0.8841 | Val Loss: 5.1226, Val R2: 0.9067\n",
      "Epoch [93/100] Train Loss: 6.8992, Train R2: 0.8838 | Val Loss: 5.1766, Val R2: 0.9060\n",
      "Epoch [94/100] Train Loss: 6.8171, Train R2: 0.8845 | Val Loss: 5.2335, Val R2: 0.9052\n",
      "Epoch [95/100] Train Loss: 6.9821, Train R2: 0.8847 | Val Loss: 5.1603, Val R2: 0.9062\n",
      "Epoch [96/100] Train Loss: 7.1302, Train R2: 0.8851 | Val Loss: 5.1922, Val R2: 0.9056\n",
      "Epoch [97/100] Train Loss: 6.7855, Train R2: 0.8844 | Val Loss: 5.2392, Val R2: 0.9052\n",
      "Epoch [98/100] Train Loss: 6.7513, Train R2: 0.8855 | Val Loss: 5.0514, Val R2: 0.9083\n",
      "Epoch [99/100] Train Loss: 6.9581, Train R2: 0.8853 | Val Loss: 5.0720, Val R2: 0.9079\n",
      "Epoch [100/100] Train Loss: 6.8685, Train R2: 0.8851 | Val Loss: 5.0815, Val R2: 0.9077\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_batch = y_batch.squeeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch) \n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        all_preds.append(outputs.detach().cpu())\n",
    "        all_targets.append(y_batch.detach().cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    train_r2 = r_squared(all_targets, all_preds)\n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    all_val_preds = []\n",
    "    all_val_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch = X_val_batch.to(device)\n",
    "            y_val_batch = y_val_batch.to(device)\n",
    "            y_val_batch = y_val_batch.squeeze(1)\n",
    "\n",
    "            val_outputs = model(X_val_batch)\n",
    "            val_loss = criterion(val_outputs, y_val_batch)\n",
    "\n",
    "            val_losses.append(val_loss.item())\n",
    "            all_val_preds.append(val_outputs.detach().cpu())\n",
    "            all_val_targets.append(y_val_batch.detach().cpu())\n",
    "        \n",
    "        all_val_preds = torch.cat(all_val_preds)\n",
    "        all_val_targets = torch.cat(all_val_targets)\n",
    "        val_r2 = r_squared(all_val_targets, all_val_preds)\n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{NUM_EPOCHS}] \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Train R2: {train_r2:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val R2: {val_r2:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fad60534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R2: 0.8837\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_test_preds = []\n",
    "all_test_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_test_batch, y_test_batch in test_loader:\n",
    "        X_test_batch = X_test_batch.to(device)\n",
    "        y_test_batch = y_test_batch.to(device)\n",
    "        y_test_batch = y_test_batch.squeeze(1)\n",
    "\n",
    "        test_outputs = model(X_test_batch)\n",
    "\n",
    "        all_test_preds.append(test_outputs.detach().cpu())\n",
    "        all_test_targets.append(y_test_batch.detach().cpu())\n",
    "    \n",
    "all_test_preds = torch.cat(all_test_preds)\n",
    "all_test_targets = torch.cat(all_test_targets)\n",
    "test_r2 = r_squared(all_test_targets, all_test_preds)\n",
    "print(f\"Test R2: {test_r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
